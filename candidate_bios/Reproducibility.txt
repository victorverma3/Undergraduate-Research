Ensuring the reproducibility of research is of great importance, and numerous measures were undertaken to maximize the replicability of the candidate biographical data generated through a custom Python data processing pipeline. During the Data Search phase of the pipeline, the Google Custom Search JSON API was employed, with results restricted to English-language content originating from the United States, and a Google Custom Search Engine (CSE) was utilized. Owing to the API's reliance on the ever-evolving Google Search algorithm and a CSE, the four source URLs used to gather each candidate's biodata were recorded in the "Sources" column of the final data output, "outputs-all.csv.", to mitigate the potential loss of access to a source or alterations in the page content In the Data Retrieval phase, the source pages were scraped to create a ChatGPT prompt for each candidate. All prompts were stored in the "ChatGPT Prompt" column of the file "retrievals-base-all.csv." 

The Data Extraction phase leveraged the Chat Completions Endpoint and the gpt-3.5-turbo-0613 model of the OpenAI API to summarize and extract the desired candidate biodata from the given ChatGPT prompt for each candidate. At the time of executing the pipeline and gathering the data (Fall 2023), these were the latest and most cost-efficient endpoints and models available. However, it is noteworthy that the gpt-3.5-turbo-0613 model is scheduled for deprecation on June 13th, 2024. Newer, more powerful OpenAI API models may exhibit enhanced efficacy in summarizing and extracting the desired candidate biodata, potentially producing output with fewer false positives and more comprehensive information. Additionally, as with all large-language models, ChatGPT is non-deterministic, implying that the same input can produce different outputs due to the inherent structure of the technology. To maximize the deterministic output, the temperature parameter of the API was set to 0. In retrospect, defining the seed parameter in the API would have been prudent, as repeated requests with the same seed and parameters would then return identical results. However, it is worth noting that OpenAI does not guarantee determinism in this configuration, so it may not have significantly impacted the outcomes. Given the relatively small prompt size for each candidate (a maximum length of 4096 tokens) and the objective nature of the desired candidate biodata, it is anticipated that the ChatGPT responses should typically remain consistent. Nevertheless, fields with more extensive information were observed to exhibit slight variations in their responses; in particular, when the "Work History" consisted of an extensive list of jobs, there were inconsistencies in the number of jobs listed in the output.

Sources
https://platform.openai.com/docs/api-reference